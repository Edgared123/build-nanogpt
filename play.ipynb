{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.8 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/43.8 kB 217.9 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 41.0/43.8 kB 281.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.8/43.8 kB 268.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\edgar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.15.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\edgar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\edgar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\edgar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\edgar\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/9.1 MB 11.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.7/9.1 MB 8.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.1/9.1 MB 8.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.4/9.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.8/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.1/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.5/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.8/9.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.3/9.1 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.6/9.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.9/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.1/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.4/9.1 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.9/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.2/9.1 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/9.1 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.8/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.1/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.4/9.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.8/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.1/9.1 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.4/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.0/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.3/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.7 kB ? eta -:--:--\n",
      "   ------------------------------------- - 389.1/401.7 kB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 401.7/401.7 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/15.5 MB 11.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.7/15.5 MB 8.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.0/15.5 MB 8.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.3/15.5 MB 7.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.5 MB 8.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.9/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.0/15.5 MB 7.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.0/15.5 MB 7.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.7/15.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.0/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.3/15.5 MB 7.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.7/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.0/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.3/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.7/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.3/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.5/15.5 MB 7.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.8/15.5 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.1/15.5 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.1/15.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.3/15.5 MB 6.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.9/15.5 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.2/15.5 MB 7.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.5/15.5 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.8/15.5 MB 7.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.1/15.5 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.4/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.7/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.0/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.3/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.6/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.0/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.4/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.0/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.4/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.7/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.2/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.5/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.8/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.3/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.6/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.8/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.2/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.7/138.7 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 268.5/268.5 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp312-none-win_amd64.whl (289 kB)\n",
      "   ---------------------------------------- 0.0/289.4 kB ? eta -:--:--\n",
      "   --------------------------------------  286.7/289.4 kB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 289.4/289.4 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.7/2.2 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 164.4/164.4 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.4/100.4 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.8/66.8 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.1/121.1 kB 6.9 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.6.2 charset-normalizer-3.3.2 huggingface-hub-0.23.3 idna-3.7 numpy-1.26.4 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.3 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.2 urllib3-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\edgar\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([50257, 768])\n",
      "transformer.wpe.weight torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight torch.Size([768])\n",
      "transformer.h.0.ln_1.bias torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.0.ln_2.weight torch.Size([768])\n",
      "transformer.h.0.ln_2.bias torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_1.weight torch.Size([768])\n",
      "transformer.h.1.ln_1.bias torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_2.weight torch.Size([768])\n",
      "transformer.h.1.ln_2.bias torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_1.weight torch.Size([768])\n",
      "transformer.h.2.ln_1.bias torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_2.weight torch.Size([768])\n",
      "transformer.h.2.ln_2.bias torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_1.weight torch.Size([768])\n",
      "transformer.h.3.ln_1.bias torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_2.weight torch.Size([768])\n",
      "transformer.h.3.ln_2.bias torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_1.weight torch.Size([768])\n",
      "transformer.h.4.ln_1.bias torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_2.weight torch.Size([768])\n",
      "transformer.h.4.ln_2.bias torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_1.weight torch.Size([768])\n",
      "transformer.h.5.ln_1.bias torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_2.weight torch.Size([768])\n",
      "transformer.h.5.ln_2.bias torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_1.weight torch.Size([768])\n",
      "transformer.h.6.ln_1.bias torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_2.weight torch.Size([768])\n",
      "transformer.h.6.ln_2.bias torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_1.weight torch.Size([768])\n",
      "transformer.h.7.ln_1.bias torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_2.weight torch.Size([768])\n",
      "transformer.h.7.ln_2.bias torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_1.weight torch.Size([768])\n",
      "transformer.h.8.ln_1.bias torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_2.weight torch.Size([768])\n",
      "transformer.h.8.ln_2.bias torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_1.weight torch.Size([768])\n",
      "transformer.h.9.ln_1.bias torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_2.weight torch.Size([768])\n",
      "transformer.h.9.ln_2.bias torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_1.weight torch.Size([768])\n",
      "transformer.h.10.ln_1.bias torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_2.weight torch.Size([768])\n",
      "transformer.h.10.ln_2.bias torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_1.weight torch.Size([768])\n",
      "transformer.h.11.ln_1.bias torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_2.weight torch.Size([768])\n",
      "transformer.h.11.ln_2.bias torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.ln_f.weight torch.Size([768])\n",
      "transformer.ln_f.bias torch.Size([768])\n",
      "lm_head.weight torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0188, -0.1974,  0.0040,  0.0113,  0.0638, -0.1050,  0.0369, -0.1680,\n",
       "        -0.0491, -0.0565, -0.0025,  0.0135, -0.0042,  0.0151,  0.0166, -0.1381,\n",
       "        -0.0063, -0.0461,  0.0267, -0.2042])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_hf[\"transformer.wpe.weight\"].view(-1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(sd_hf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer.wpe.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(sd_hf[\"transformer.wpe.weight\"], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 150])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 200])\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sd_hf[\"transformer.h.1.attn.c_attn.weight\"][:300,:300], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's instead sample manually\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "tokens = [15496, 11, 314, 1101, 257, 3303, 2746, 11] # \"Hello, I'm a language model,\"\n",
    "tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(5, 1) # (5, 8)\n",
    "x = tokens.to('cuda')\n",
    "\n",
    "# generate!\n",
    "while x.size(1) < 30: # max_length=30\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0] # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# print the generated text\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "for i in range(5):\n",
    "    tokens = x[i, :30].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny shakespeare dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "data = text[:1000] # first 1,000 characters\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(data)\n",
    "print(tokens[:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "buf = torch.tensor(tokens[:24 + 1])\n",
    "x = buf[:-1].view(4, 6)\n",
    "y = buf[1:].view(4, 6)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf[\"lm_head.weight\"].shape)\n",
    "print(sd_hf[\"transformer.wte.weight\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sd_hf[\"lm_head.weight\"] == sd_hf[\"transformer.wte.weight\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd_hf[\"lm_head.weight\"].data_ptr())\n",
    "print(sd_hf[\"transformer.wte.weight\"].data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# standard deviation grows inside the residual stream\n",
    "x = torch.zeros(768)\n",
    "n = 100 # e.g. 100 layers\n",
    "for i in range(n):\n",
    "    x += n**-0.5 * torch.randn(768)\n",
    "\n",
    "print(x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# super simple little MLP\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(16, 32),\n",
    "    torch.nn.GELU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    ")\n",
    "torch.random.manual_seed(42)\n",
    "x = torch.randn(4, 16)\n",
    "y = torch.randn(4, 1)\n",
    "net.zero_grad()\n",
    "yhat = net(x)\n",
    "loss = torch.nn.functional.mse_loss(yhat, y)\n",
    "loss.backward()\n",
    "print(net[0].weight.grad.view(-1)[:10])\n",
    "\n",
    "# the loss objective here is (due to readuction='mean')\n",
    "# L = 1/4 * [\n",
    "#            (y[0] - yhat[0])**2 +\n",
    "#            (y[1] - yhat[1])**2 +\n",
    "#            (y[2] - yhat[2])**2 +\n",
    "#            (y[3] - yhat[3])**2\n",
    "#           ]\n",
    "# NOTE: 1/4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do it with grad_accum_steps of 4, and B=1\n",
    "# the loss objective here is different because\n",
    "# accumulation in gradient <---> SUM in loss\n",
    "# i.e. we instead get:\n",
    "# L0 = 1/4(y[0] - yhat[0])**2\n",
    "# L1 = 1/4(y[1] - yhat[1])**2\n",
    "# L2 = 1/4(y[2] - yhat[2])**2\n",
    "# L3 = 1/4(y[3] - yhat[3])**2\n",
    "# L = L0 + L1 + L2 + L3\n",
    "# NOTE: the \"normalizer\" of 1/4 is lost\n",
    "net.zero_grad()\n",
    "for i in range(4):\n",
    "    yhat = net(x[i])\n",
    "    loss = torch.nn.functional.mse_loss(yhat, y[i])\n",
    "    loss = loss / 4 # <-- have to add back the \"normalizer\"!\n",
    "    loss.backward()\n",
    "print(net[0].weight.grad.view(-1)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse and visualize the logfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sz = \"124M\"\n",
    "\n",
    "loss_baseline = {\n",
    "    \"124M\": 3.2924,\n",
    "}[sz]\n",
    "hella2_baseline = { # HellaSwag for GPT-2\n",
    "    \"124M\": 0.294463,\n",
    "    \"350M\": 0.375224,\n",
    "    \"774M\": 0.431986,\n",
    "    \"1558M\": 0.488946,\n",
    "}[sz]\n",
    "hella3_baseline = { # HellaSwag for GPT-3\n",
    "    \"124M\": 0.337,\n",
    "    \"350M\": 0.436,\n",
    "    \"774M\": 0.510,\n",
    "    \"1558M\": 0.547,\n",
    "}[sz]\n",
    "\n",
    "# load the log file\n",
    "with open(\"log124M_40B/log.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# parse the individual lines, group by stream (train,val,hella)\n",
    "streams = {}\n",
    "for line in lines:\n",
    "    step, stream, val = line.strip().split()\n",
    "    if stream not in streams:\n",
    "        streams[stream] = {}\n",
    "    streams[stream][int(step)] = float(val)\n",
    "\n",
    "# convert each stream from {step: val} to (steps[], vals[])\n",
    "# so it's easier for plotting\n",
    "streams_xy = {}\n",
    "for k, v in streams.items():\n",
    "    # get all (step, val) items, sort them\n",
    "    xy = sorted(list(v.items()))\n",
    "    # unpack the list of tuples to tuple of lists\n",
    "    streams_xy[k] = list(zip(*xy))\n",
    "\n",
    "# create figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Panel 1: losses: both train and val\n",
    "plt.subplot(121)\n",
    "xs, ys = streams_xy[\"train\"] # training loss\n",
    "ys = np.array(ys)\n",
    "plt.plot(xs, ys, label=f'nanogpt ({sz}) train loss')\n",
    "print(\"Min Train Loss:\", min(ys))\n",
    "xs, ys = streams_xy[\"val\"] # validation loss\n",
    "plt.plot(xs, ys, label=f'nanogpt ({sz}) val loss')\n",
    "# horizontal line at GPT-2 baseline\n",
    "if loss_baseline is not None:\n",
    "    plt.axhline(y=loss_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) checkpoint val loss\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.yscale('log')\n",
    "plt.ylim(0.0, 4.0)\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "print(\"Min Validation Loss:\", min(ys))\n",
    "\n",
    "# Panel 2: HellaSwag eval\n",
    "plt.subplot(122)\n",
    "xs, ys = streams_xy[\"hella\"] # HellaSwag eval\n",
    "ys = np.array(ys)\n",
    "plt.plot(xs, ys, label=f\"nanogpt ({sz})\")\n",
    "# horizontal line at GPT-2 baseline\n",
    "if hella2_baseline:\n",
    "    plt.axhline(y=hella2_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) checkpoint\")\n",
    "if hella3_baseline:\n",
    "    plt.axhline(y=hella3_baseline, color='g', linestyle='--', label=f\"OpenAI GPT-3 ({sz}) checkpoint\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"HellaSwag eval\")\n",
    "print(\"Max Hellaswag eval:\", max(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
